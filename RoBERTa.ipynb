{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "liable-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer, AdamW\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n",
    "import pickle\n",
    "from tqdm import tqdm, trange\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "otherwise-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lesser-addiction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Every actor along the agriculture supply chain...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The recent increase in food insecurity was pri...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Number of companies publishing sustainability ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Much work has been done recently to improve ci...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Of the 172 countries that reported in 2018, 60...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  labels\n",
       "0  Every actor along the agriculture supply chain...       2\n",
       "1  The recent increase in food insecurity was pri...       2\n",
       "2  Number of companies publishing sustainability ...      12\n",
       "3  Much work has been done recently to improve ci...      16\n",
       "4  Of the 172 countries that reported in 2018, 60...       6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load training data\n",
    "df = pd.read_csv('./data/training_set.csv', delimiter=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adjacent-filling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique comments:  False\n",
      "Null values:  False\n",
      "average sentence length:  22.248170094109447\n",
      "stdev sentence length:  11.464921040506532\n"
     ]
    }
   ],
   "source": [
    "print('Unique comments: ', df.sentence.nunique() == df.shape[0])\n",
    "print('Null values: ', df.isnull().values.any())\n",
    "print('average sentence length: ', df.sentence.str.split().str.len().mean())\n",
    "print('stdev sentence length: ', df.sentence.str.split().str.len().std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "universal-watts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Access to financial services.</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>Access to financial services.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>Access to quality essential health care servic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>Access to quality essential health care servic...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5151</th>\n",
       "      <td>Adopt the Children’s Rights and Business Princ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>Adopt the Children’s Rights and Business Princ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3860</th>\n",
       "      <td>Apply these principles to help maximize the po...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>Apply these principles to help maximize the po...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290</th>\n",
       "      <td>Availability of a skilled workforce.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>Availability of a skilled workforce.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Availability of products and services for thos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>Availability of products and services for thos...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>Basic rights include freedom of speech, privac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Basic rights include freedom of speech, privac...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3719</th>\n",
       "      <td>Beyond these minimum requirements, companies c...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>Beyond these minimum requirements, companies c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5050</th>\n",
       "      <td>Businesses have minimum responsibilities to me...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>Businesses have minimum responsibilities to me...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>By joining the world’s largest business initia...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>By joining the world’s largest business initia...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>Capacity Building.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>Capacity Building.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5609</th>\n",
       "      <td>Capacity Building.</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>Children are key stakeholders of your business...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4444</th>\n",
       "      <td>Children are key stakeholders of your business...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>Companies that focus on protecting human right...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>Companies that focus on protecting human right...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Develop products and services tailored for poo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>Develop products and services tailored for poo...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>Diversity and equal opportunity.</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4754</th>\n",
       "      <td>Diversity and equal opportunity.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>Domestic material consumption, domestic materi...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>Domestic material consumption, domestic materi...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3117</th>\n",
       "      <td>Economic inclusion.</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>Economic inclusion.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>Electricity availability and reliability.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3324</th>\n",
       "      <td>Electricity availability and reliability.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>Energy efficiency.</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>Energy efficiency.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791</th>\n",
       "      <td>Environmental investments.</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5593</th>\n",
       "      <td>Environmental investments.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>Environmental investments.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>Environmental investments.</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>Equal remuneration for women and men.</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Equal remuneration for women and men.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>For example, they can create diverse and inclu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>For example, they can create diverse and inclu...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>Human rights are universal and every person ar...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>Human rights are universal and every person ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>Improve access to basic goods and services for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5128</th>\n",
       "      <td>Improve access to basic goods and services for...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>In an increasingly interconnected world, there...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>In an increasingly interconnected world, there...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>Infrastructure investments.</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>Infrastructure investments.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4200</th>\n",
       "      <td>Infrastructure investments.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>Invest in business-driven poverty eradication ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>Invest in business-driven poverty eradication ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>Link current efforts to a UN-led initiative.</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3625</th>\n",
       "      <td>Link current efforts to a UN-led initiative.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>Material footprint, material footprint per cap...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4339</th>\n",
       "      <td>Material footprint, material footprint per cap...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5188</th>\n",
       "      <td>Mobilized amount of United States dollars per ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>Mobilized amount of United States dollars per ...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>Mobilizing a critical mass of business leaders...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>Mobilizing a critical mass of business leaders...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>Non-discrimination.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>Non-discrimination.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>Number of countries with national and local di...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3703</th>\n",
       "      <td>Number of countries with national and local di...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>Number of countries with national and local di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>Number of deaths, missing persons and persons ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>Number of deaths, missing persons and persons ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065</th>\n",
       "      <td>Number of deaths, missing persons and persons ...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>Over that period, climate-related and geophysi...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5591</th>\n",
       "      <td>Over that period, climate-related and geophysi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818</th>\n",
       "      <td>Participants sign the Caring for Climate State...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>Participants sign the Caring for Climate State...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>Partner with civil society networks to provide...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4750</th>\n",
       "      <td>Partner with civil society networks to provide...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4466</th>\n",
       "      <td>Proportion of members and voting rights of dev...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>Proportion of members and voting rights of dev...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>Recruit, train and employ local community memb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>Recruit, train and employ local community memb...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>Secure dignity and equality for all human bein...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>Secure dignity and equality for all human bein...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Shape the climate change policy agenda.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>Shape the climate change policy agenda.</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>Share best and emerging practices with peers a...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4159</th>\n",
       "      <td>Share best and emerging practices with peers a...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Sustainable sourcing.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669</th>\n",
       "      <td>Sustainable sourcing.</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>Sustainable sourcing.</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5219</th>\n",
       "      <td>The Principles outline what you can do in the ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>The Principles outline what you can do in the ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>The Principles provide a framework for busines...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>The Principles provide a framework for busines...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>The Principles were developed by UNICEF, the U...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>The Principles were developed by UNICEF, the U...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>The UN Global Compact promotes tools and resou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3927</th>\n",
       "      <td>The UN Global Compact promotes tools and resou...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>The human rights principles (Principles 1 and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>The human rights principles (Principles 1 and ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5065</th>\n",
       "      <td>These action steps are built on and aligned wi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>These action steps are built on and aligned wi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4555</th>\n",
       "      <td>They must act with due diligence to avoid infr...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>They must act with due diligence to avoid infr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612</th>\n",
       "      <td>They must also abide by international standard...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>They must also abide by international standard...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>This may include setting greenhouse gas emissi...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>This may include setting greenhouse gas emissi...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>This means they must address any negative huma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5386</th>\n",
       "      <td>This means they must address any negative huma...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>Through Caring for Climate, the UN Global Comp...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>Through Caring for Climate, the UN Global Comp...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>To learn more, visit the Children's Rights and...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>To learn more, visit the Children's Rights and...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>To make a lasting commitment to address climat...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4643</th>\n",
       "      <td>To make a lasting commitment to address climat...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3884</th>\n",
       "      <td>We also offer engagement opportunities to help...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>We also offer engagement opportunities to help...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>We call on companies to respect and support in...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>We call on companies to respect and support in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>We invite you to adopt the Children’s Rights a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4039</th>\n",
       "      <td>We invite you to adopt the Children’s Rights a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>We offer a range of tools and resources to hel...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>We offer a range of tools and resources to hel...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4528</th>\n",
       "      <td>While Governments have the duty to protect ind...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>While Governments have the duty to protect ind...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>While these types of actions to support human ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>While these types of actions to support human ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>develop living wage policy).</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>develop living wage policy).</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>mobile based money transfer services for unban...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5525</th>\n",
       "      <td>mobile based money transfer services for unban...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>through core business, policy dialogue, social...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>through core business, policy dialogue, social...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  labels\n",
       "46                       Access to financial services.       10\n",
       "1466                     Access to financial services.        9\n",
       "1442  Access to quality essential health care servic...       1\n",
       "938   Access to quality essential health care servic...       3\n",
       "5151  Adopt the Children’s Rights and Business Princ...       4\n",
       "2249  Adopt the Children’s Rights and Business Princ...       5\n",
       "3860  Apply these principles to help maximize the po...       4\n",
       "3593  Apply these principles to help maximize the po...       5\n",
       "3290              Availability of a skilled workforce.        4\n",
       "2177              Availability of a skilled workforce.        8\n",
       "227   Availability of products and services for thos...       1\n",
       "2234  Availability of products and services for thos...      10\n",
       "4578  Basic rights include freedom of speech, privac...       1\n",
       "616   Basic rights include freedom of speech, privac...      10\n",
       "3719  Beyond these minimum requirements, companies c...      10\n",
       "731   Beyond these minimum requirements, companies c...       1\n",
       "5050  Businesses have minimum responsibilities to me...       1\n",
       "2928  Businesses have minimum responsibilities to me...      10\n",
       "4320  By joining the world’s largest business initia...      13\n",
       "1551  By joining the world’s largest business initia...       7\n",
       "2302                                Capacity Building.        8\n",
       "3179                                Capacity Building.        4\n",
       "5609                                Capacity Building.       10\n",
       "2899  Children are key stakeholders of your business...       4\n",
       "4444  Children are key stakeholders of your business...       5\n",
       "769   Companies that focus on protecting human right...      10\n",
       "5034  Companies that focus on protecting human right...       1\n",
       "265   Develop products and services tailored for poo...       1\n",
       "3262  Develop products and services tailored for poo...      10\n",
       "2069                  Diversity and equal opportunity.       10\n",
       "4754                  Diversity and equal opportunity.        5\n",
       "869   Domestic material consumption, domestic materi...      12\n",
       "2642  Domestic material consumption, domestic materi...       8\n",
       "3117                               Economic inclusion.       10\n",
       "4681                               Economic inclusion.        8\n",
       "4196         Electricity availability and reliability.        7\n",
       "3324         Electricity availability and reliability.        1\n",
       "1359                                Energy efficiency.       13\n",
       "773                                 Energy efficiency.        7\n",
       "2791                        Environmental investments.       13\n",
       "5593                        Environmental investments.        9\n",
       "1031                        Environmental investments.        7\n",
       "4602                        Environmental investments.       14\n",
       "3200             Equal remuneration for women and men.       10\n",
       "1999             Equal remuneration for women and men.        5\n",
       "2581  For example, they can create diverse and inclu...       1\n",
       "2488  For example, they can create diverse and inclu...      10\n",
       "2588  Human rights are universal and every person ar...      10\n",
       "955   Human rights are universal and every person ar...       1\n",
       "5109  Improve access to basic goods and services for...       1\n",
       "5128  Improve access to basic goods and services for...      10\n",
       "5727  In an increasingly interconnected world, there...       1\n",
       "639   In an increasingly interconnected world, there...      10\n",
       "3727                       Infrastructure investments.       11\n",
       "952                        Infrastructure investments.        7\n",
       "4200                       Infrastructure investments.        9\n",
       "777   Invest in business-driven poverty eradication ...      10\n",
       "2790  Invest in business-driven poverty eradication ...       1\n",
       "2030      Link current efforts to a UN-led initiative.       13\n",
       "3625      Link current efforts to a UN-led initiative.        7\n",
       "5001  Material footprint, material footprint per cap...       8\n",
       "4339  Material footprint, material footprint per cap...      12\n",
       "5188  Mobilized amount of United States dollars per ...       7\n",
       "3004  Mobilized amount of United States dollars per ...      13\n",
       "2217  Mobilizing a critical mass of business leaders...      13\n",
       "2751  Mobilizing a critical mass of business leaders...       7\n",
       "1475                               Non-discrimination.        1\n",
       "2676                               Non-discrimination.        8\n",
       "2722  Number of countries with national and local di...      11\n",
       "3703  Number of countries with national and local di...      13\n",
       "1197  Number of countries with national and local di...       1\n",
       "628   Number of deaths, missing persons and persons ...       1\n",
       "662   Number of deaths, missing persons and persons ...      11\n",
       "3065  Number of deaths, missing persons and persons ...      13\n",
       "2003  Over that period, climate-related and geophysi...      13\n",
       "5591  Over that period, climate-related and geophysi...       1\n",
       "2818  Participants sign the Caring for Climate State...       7\n",
       "4397  Participants sign the Caring for Climate State...      13\n",
       "2594  Partner with civil society networks to provide...      10\n",
       "4750  Partner with civil society networks to provide...       1\n",
       "4466  Proportion of members and voting rights of dev...      16\n",
       "1921  Proportion of members and voting rights of dev...      10\n",
       "2991  Recruit, train and employ local community memb...       1\n",
       "2190  Recruit, train and employ local community memb...      10\n",
       "3230  Secure dignity and equality for all human bein...       1\n",
       "1142  Secure dignity and equality for all human bein...      10\n",
       "207            Shape the climate change policy agenda.        7\n",
       "5145           Shape the climate change policy agenda.       13\n",
       "2816  Share best and emerging practices with peers a...       7\n",
       "4159  Share best and emerging practices with peers a...      13\n",
       "262                              Sustainable sourcing.        2\n",
       "5669                             Sustainable sourcing.       14\n",
       "2385                             Sustainable sourcing.       12\n",
       "5219  The Principles outline what you can do in the ...       5\n",
       "1470  The Principles outline what you can do in the ...       4\n",
       "1786  The Principles provide a framework for busines...       4\n",
       "5007  The Principles provide a framework for busines...       5\n",
       "2090  The Principles were developed by UNICEF, the U...       5\n",
       "2891  The Principles were developed by UNICEF, the U...       4\n",
       "1199  The UN Global Compact promotes tools and resou...       1\n",
       "3927  The UN Global Compact promotes tools and resou...      10\n",
       "367   The human rights principles (Principles 1 and ...       1\n",
       "894   The human rights principles (Principles 1 and ...      10\n",
       "5065  These action steps are built on and aligned wi...       4\n",
       "1107  These action steps are built on and aligned wi...       5\n",
       "4555  They must act with due diligence to avoid infr...      10\n",
       "1985  They must act with due diligence to avoid infr...       1\n",
       "4612  They must also abide by international standard...      10\n",
       "2127  They must also abide by international standard...       1\n",
       "1700  This may include setting greenhouse gas emissi...       7\n",
       "5391  This may include setting greenhouse gas emissi...      13\n",
       "2851  This means they must address any negative huma...       1\n",
       "5386  This means they must address any negative huma...      10\n",
       "2885  Through Caring for Climate, the UN Global Comp...       7\n",
       "1094  Through Caring for Climate, the UN Global Comp...      13\n",
       "5514  To learn more, visit the Children's Rights and...       5\n",
       "302   To learn more, visit the Children's Rights and...       4\n",
       "1944  To make a lasting commitment to address climat...      13\n",
       "4643  To make a lasting commitment to address climat...       7\n",
       "3884  We also offer engagement opportunities to help...      10\n",
       "998   We also offer engagement opportunities to help...       1\n",
       "2342  We call on companies to respect and support in...      10\n",
       "1218  We call on companies to respect and support in...       1\n",
       "1796  We invite you to adopt the Children’s Rights a...       4\n",
       "4039  We invite you to adopt the Children’s Rights a...       5\n",
       "1450  We offer a range of tools and resources to hel...       5\n",
       "1612  We offer a range of tools and resources to hel...       4\n",
       "4528  While Governments have the duty to protect ind...      10\n",
       "815   While Governments have the duty to protect ind...       1\n",
       "962   While these types of actions to support human ...      10\n",
       "4800  While these types of actions to support human ...       1\n",
       "693                       develop living wage policy).       10\n",
       "1231                      develop living wage policy).        1\n",
       "1630  mobile based money transfer services for unban...       1\n",
       "5525  mobile based money transfer services for unban...      10\n",
       "900   through core business, policy dialogue, social...       1\n",
       "1907  through core business, policy dialogue, social...      10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "df[df.sentence.duplicated(keep=False)].sort_values('sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "chief-reflection",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     600\n",
       "17    470\n",
       "3     410\n",
       "16    365\n",
       "6     334\n",
       "15    331\n",
       "12    324\n",
       "2     295\n",
       "5     291\n",
       "11    287\n",
       "8     277\n",
       "1     274\n",
       "10    268\n",
       "4     258\n",
       "13    257\n",
       "14    235\n",
       "7     235\n",
       "9     227\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eleven-welding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "      <th>one_hot_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Every actor along the agriculture supply chain...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The recent increase in food insecurity was pri...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Number of companies publishing sustainability ...</td>\n",
       "      <td>12</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Much work has been done recently to improve ci...</td>\n",
       "      <td>16</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Of the 172 countries that reported in 2018, 60...</td>\n",
       "      <td>6</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  labels  \\\n",
       "0  Every actor along the agriculture supply chain...       2   \n",
       "1  The recent increase in food insecurity was pri...       2   \n",
       "2  Number of companies publishing sustainability ...      12   \n",
       "3  Much work has been done recently to improve ci...      16   \n",
       "4  Of the 172 countries that reported in 2018, 60...       6   \n",
       "\n",
       "                                      one_hot_labels  \n",
       "0  (0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  (0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "3  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RoBERTa model requires single column one-hot-encoded labels \n",
    "# this function returns this format from the usual numeric class label\n",
    "def one_hot_encode(class_number):\n",
    "    \"\"\"\n",
    "    Gets an integer as argument representing the target class label. \n",
    "    As RoBERTa needs the targets in tuple one_hot_encoded format, \n",
    "    a tuple is returned which has a 1 at the position of the target class. \n",
    "    E.g. 2 -> (0,0,1,0,0,...)\n",
    "    \"\"\"\n",
    "    num_classes = 18\n",
    "    t = [0 for i in range(num_classes)]\n",
    "    t[class_number] = 1\n",
    "    return tuple(t)\n",
    "\n",
    "# apply one hot encoding.\n",
    "df['one_hot_labels'] = df['labels'].apply(lambda x: one_hot_encode(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interim-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(df.sentence)\n",
    "labels = list(df.one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fuzzy-dragon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer outputs:  dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=False) # tokenizer\n",
    "#encoded_input = tokenizer(sentences, return_tensors='pt')\n",
    "encodings = tokenizer.batch_encode_plus(sentences, return_token_type_ids=True, padding=True)\n",
    "#encodings = tokenizer.batch_encode_plus(comments,max_length=max_length,pad_to_max_length=True) # tokenizer's encoding method\n",
    "print('tokenizer outputs: ', encodings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "completed-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = encodings['input_ids'] # tokenized and encoded sentences\n",
    "token_type_ids = encodings['token_type_ids'] # token type ids\n",
    "attention_masks = encodings['attention_mask'] # attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "exciting-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets\n",
    "\n",
    "train_inputs, validation_inputs, train_labels, validation_labels, train_token_types, validation_token_types, train_masks, validation_masks = train_test_split(input_ids, labels, token_type_ids, attention_masks, random_state=42, test_size=0.10, stratify = labels)\n",
    "\n",
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "train_token_types = torch.tensor(train_token_types)\n",
    "\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "validation_token_types = torch.tensor(validation_token_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "accomplished-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a batch size for training. For fine-tuning with XLNet, the authors recommend a batch size of 32, 48, or 128. We will use 32 here to avoid memory issues.\n",
    "batch_size = 32\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels, train_token_types)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, )\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels, validation_token_types)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "nb_train_inputs = len(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "muslim-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(validation_dataloader,'validation_data_loader')\n",
    "torch.save(train_dataloader,'train_data_loader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "going-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load model, the pretrained model will include a single linear classification layer on top for classification. \n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "synthetic-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5)  # Default optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "emotional-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "small-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_remaining_time(start, time, nb_training_data):\n",
    "    t_diff = time - start\n",
    "    frac_todo = (nb_train_inputs - nb_training_data) / nb_train_inputs\n",
    "    frac_done = 1 - frac_todo\n",
    "    t_est = (t_diff / frac_done) - t_diff\n",
    "    print('Est. Remaining Time Till Epoch: {}min'.format(round(t_est/60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "electronic-tract",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|                                                                  | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est. Remaining Time Till Epoch: 87.53min\n",
      "Est. Remaining Time Till Epoch: 87.16min\n",
      "Est. Remaining Time Till Epoch: 86.28min\n",
      "Est. Remaining Time Till Epoch: 85.67min\n",
      "Est. Remaining Time Till Epoch: 85.14min\n",
      "Est. Remaining Time Till Epoch: 84.49min\n",
      "Est. Remaining Time Till Epoch: 83.88min\n",
      "Est. Remaining Time Till Epoch: 83.73min\n",
      "Est. Remaining Time Till Epoch: 83.29min\n",
      "Est. Remaining Time Till Epoch: 83.23min\n",
      "Est. Remaining Time Till Epoch: 82.7min\n",
      "Est. Remaining Time Till Epoch: 82.11min\n",
      "Est. Remaining Time Till Epoch: 81.52min\n",
      "Est. Remaining Time Till Epoch: 80.97min\n",
      "Est. Remaining Time Till Epoch: 80.41min\n",
      "Est. Remaining Time Till Epoch: 79.82min\n",
      "Est. Remaining Time Till Epoch: 79.23min\n",
      "Est. Remaining Time Till Epoch: 78.68min\n",
      "Est. Remaining Time Till Epoch: 78.09min\n",
      "Est. Remaining Time Till Epoch: 77.56min\n",
      "Est. Remaining Time Till Epoch: 76.97min\n",
      "Est. Remaining Time Till Epoch: 76.4min\n",
      "Est. Remaining Time Till Epoch: 75.84min\n",
      "Est. Remaining Time Till Epoch: 75.28min\n",
      "Est. Remaining Time Till Epoch: 74.72min\n",
      "Est. Remaining Time Till Epoch: 74.17min\n",
      "Est. Remaining Time Till Epoch: 73.61min\n",
      "Est. Remaining Time Till Epoch: 73.05min\n",
      "Est. Remaining Time Till Epoch: 72.49min\n",
      "Est. Remaining Time Till Epoch: 71.94min\n",
      "Est. Remaining Time Till Epoch: 71.41min\n",
      "Est. Remaining Time Till Epoch: 70.85min\n",
      "Est. Remaining Time Till Epoch: 70.29min\n",
      "Est. Remaining Time Till Epoch: 69.74min\n",
      "Est. Remaining Time Till Epoch: 69.19min\n",
      "Est. Remaining Time Till Epoch: 68.63min\n",
      "Est. Remaining Time Till Epoch: 68.09min\n",
      "Est. Remaining Time Till Epoch: 67.52min\n",
      "Est. Remaining Time Till Epoch: 66.97min\n",
      "Est. Remaining Time Till Epoch: 66.43min\n",
      "Est. Remaining Time Till Epoch: 65.86min\n",
      "Est. Remaining Time Till Epoch: 65.32min\n",
      "Est. Remaining Time Till Epoch: 64.78min\n",
      "Est. Remaining Time Till Epoch: 64.23min\n",
      "Est. Remaining Time Till Epoch: 63.68min\n",
      "Est. Remaining Time Till Epoch: 63.13min\n",
      "Est. Remaining Time Till Epoch: 62.57min\n",
      "Est. Remaining Time Till Epoch: 62.03min\n",
      "Est. Remaining Time Till Epoch: 61.48min\n",
      "Est. Remaining Time Till Epoch: 60.93min\n",
      "Est. Remaining Time Till Epoch: 60.39min\n",
      "Est. Remaining Time Till Epoch: 59.84min\n",
      "Est. Remaining Time Till Epoch: 59.3min\n",
      "Est. Remaining Time Till Epoch: 58.76min\n",
      "Est. Remaining Time Till Epoch: 58.21min\n",
      "Est. Remaining Time Till Epoch: 57.67min\n",
      "Est. Remaining Time Till Epoch: 57.11min\n",
      "Est. Remaining Time Till Epoch: 56.57min\n",
      "Est. Remaining Time Till Epoch: 56.03min\n",
      "Est. Remaining Time Till Epoch: 55.48min\n",
      "Est. Remaining Time Till Epoch: 54.94min\n",
      "Est. Remaining Time Till Epoch: 54.39min\n",
      "Est. Remaining Time Till Epoch: 53.84min\n",
      "Est. Remaining Time Till Epoch: 53.29min\n",
      "Est. Remaining Time Till Epoch: 52.74min\n",
      "Est. Remaining Time Till Epoch: 52.2min\n",
      "Est. Remaining Time Till Epoch: 51.66min\n",
      "Est. Remaining Time Till Epoch: 51.11min\n",
      "Est. Remaining Time Till Epoch: 50.57min\n",
      "Est. Remaining Time Till Epoch: 50.02min\n",
      "Est. Remaining Time Till Epoch: 49.47min\n",
      "Est. Remaining Time Till Epoch: 48.93min\n",
      "Est. Remaining Time Till Epoch: 48.37min\n",
      "Est. Remaining Time Till Epoch: 47.83min\n",
      "Est. Remaining Time Till Epoch: 47.28min\n",
      "Est. Remaining Time Till Epoch: 46.74min\n",
      "Est. Remaining Time Till Epoch: 46.19min\n",
      "Est. Remaining Time Till Epoch: 45.64min\n",
      "Est. Remaining Time Till Epoch: 45.09min\n",
      "Est. Remaining Time Till Epoch: 44.54min\n",
      "Est. Remaining Time Till Epoch: 43.99min\n",
      "Est. Remaining Time Till Epoch: 43.45min\n",
      "Est. Remaining Time Till Epoch: 42.9min\n",
      "Est. Remaining Time Till Epoch: 42.35min\n",
      "Est. Remaining Time Till Epoch: 41.81min\n",
      "Est. Remaining Time Till Epoch: 41.26min\n",
      "Est. Remaining Time Till Epoch: 40.71min\n",
      "Est. Remaining Time Till Epoch: 40.16min\n",
      "Est. Remaining Time Till Epoch: 39.62min\n",
      "Est. Remaining Time Till Epoch: 39.07min\n",
      "Est. Remaining Time Till Epoch: 38.52min\n",
      "Est. Remaining Time Till Epoch: 37.97min\n",
      "Est. Remaining Time Till Epoch: 37.43min\n",
      "Est. Remaining Time Till Epoch: 36.88min\n",
      "Est. Remaining Time Till Epoch: 36.33min\n",
      "Est. Remaining Time Till Epoch: 35.78min\n",
      "Est. Remaining Time Till Epoch: 35.23min\n",
      "Est. Remaining Time Till Epoch: 34.68min\n",
      "Est. Remaining Time Till Epoch: 34.13min\n",
      "Est. Remaining Time Till Epoch: 33.58min\n",
      "Est. Remaining Time Till Epoch: 33.03min\n",
      "Est. Remaining Time Till Epoch: 32.49min\n",
      "Est. Remaining Time Till Epoch: 31.94min\n",
      "Est. Remaining Time Till Epoch: 31.39min\n",
      "Est. Remaining Time Till Epoch: 30.85min\n",
      "Est. Remaining Time Till Epoch: 30.3min\n",
      "Est. Remaining Time Till Epoch: 29.75min\n",
      "Est. Remaining Time Till Epoch: 29.21min\n",
      "Est. Remaining Time Till Epoch: 28.66min\n",
      "Est. Remaining Time Till Epoch: 28.12min\n",
      "Est. Remaining Time Till Epoch: 27.57min\n",
      "Est. Remaining Time Till Epoch: 27.02min\n",
      "Est. Remaining Time Till Epoch: 26.47min\n",
      "Est. Remaining Time Till Epoch: 25.92min\n",
      "Est. Remaining Time Till Epoch: 25.38min\n",
      "Est. Remaining Time Till Epoch: 24.83min\n",
      "Est. Remaining Time Till Epoch: 24.28min\n",
      "Est. Remaining Time Till Epoch: 23.74min\n",
      "Est. Remaining Time Till Epoch: 23.19min\n",
      "Est. Remaining Time Till Epoch: 22.64min\n",
      "Est. Remaining Time Till Epoch: 22.1min\n",
      "Est. Remaining Time Till Epoch: 21.55min\n",
      "Est. Remaining Time Till Epoch: 21.01min\n",
      "Est. Remaining Time Till Epoch: 20.46min\n",
      "Est. Remaining Time Till Epoch: 19.91min\n",
      "Est. Remaining Time Till Epoch: 19.37min\n",
      "Est. Remaining Time Till Epoch: 18.82min\n",
      "Est. Remaining Time Till Epoch: 18.27min\n",
      "Est. Remaining Time Till Epoch: 17.72min\n",
      "Est. Remaining Time Till Epoch: 17.18min\n",
      "Est. Remaining Time Till Epoch: 16.63min\n",
      "Est. Remaining Time Till Epoch: 16.08min\n",
      "Est. Remaining Time Till Epoch: 15.53min\n",
      "Est. Remaining Time Till Epoch: 14.99min\n",
      "Est. Remaining Time Till Epoch: 14.44min\n",
      "Est. Remaining Time Till Epoch: 13.89min\n",
      "Est. Remaining Time Till Epoch: 13.34min\n",
      "Est. Remaining Time Till Epoch: 12.8min\n",
      "Est. Remaining Time Till Epoch: 12.25min\n",
      "Est. Remaining Time Till Epoch: 11.7min\n",
      "Est. Remaining Time Till Epoch: 11.16min\n",
      "Est. Remaining Time Till Epoch: 10.61min\n",
      "Est. Remaining Time Till Epoch: 10.06min\n",
      "Est. Remaining Time Till Epoch: 9.52min\n",
      "Est. Remaining Time Till Epoch: 8.97min\n",
      "Est. Remaining Time Till Epoch: 8.42min\n",
      "Est. Remaining Time Till Epoch: 7.87min\n",
      "Est. Remaining Time Till Epoch: 7.33min\n",
      "Est. Remaining Time Till Epoch: 6.78min\n",
      "Est. Remaining Time Till Epoch: 6.23min\n",
      "Est. Remaining Time Till Epoch: 5.68min\n",
      "Est. Remaining Time Till Epoch: 5.13min\n",
      "Est. Remaining Time Till Epoch: 4.59min\n",
      "Est. Remaining Time Till Epoch: 4.04min\n",
      "Est. Remaining Time Till Epoch: 3.49min\n",
      "Est. Remaining Time Till Epoch: 2.94min\n",
      "Est. Remaining Time Till Epoch: 2.4min\n",
      "Est. Remaining Time Till Epoch: 1.85min\n",
      "Est. Remaining Time Till Epoch: 1.3min\n",
      "Est. Remaining Time Till Epoch: 0.75min\n",
      "Est. Remaining Time Till Epoch: 0.21min\n",
      "Est. Remaining Time Till Epoch: 0.0min\n",
      "Train loss: 0.1449420459476518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████▎                                  | 1/3 [1:31:39<3:03:18, 5499.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  68.98803046789989\n",
      "Flat Validation Accuracy:  55.22648083623694\n",
      "Est. Remaining Time Till Epoch: 89.33min\n",
      "Est. Remaining Time Till Epoch: 88.49min\n",
      "Est. Remaining Time Till Epoch: 87.98min\n",
      "Est. Remaining Time Till Epoch: 87.66min\n",
      "Est. Remaining Time Till Epoch: 86.87min\n",
      "Est. Remaining Time Till Epoch: 86.28min\n",
      "Est. Remaining Time Till Epoch: 85.66min\n",
      "Est. Remaining Time Till Epoch: 85.04min\n",
      "Est. Remaining Time Till Epoch: 84.4min\n",
      "Est. Remaining Time Till Epoch: 83.85min\n",
      "Est. Remaining Time Till Epoch: 83.29min\n",
      "Est. Remaining Time Till Epoch: 82.66min\n",
      "Est. Remaining Time Till Epoch: 82.04min\n",
      "Est. Remaining Time Till Epoch: 81.58min\n",
      "Est. Remaining Time Till Epoch: 81.0min\n",
      "Est. Remaining Time Till Epoch: 80.51min\n",
      "Est. Remaining Time Till Epoch: 80.06min\n",
      "Est. Remaining Time Till Epoch: 79.52min\n",
      "Est. Remaining Time Till Epoch: 78.99min\n",
      "Est. Remaining Time Till Epoch: 78.58min\n",
      "Est. Remaining Time Till Epoch: 78.15min\n",
      "Est. Remaining Time Till Epoch: 77.65min\n",
      "Est. Remaining Time Till Epoch: 77.14min\n",
      "Est. Remaining Time Till Epoch: 76.62min\n",
      "Est. Remaining Time Till Epoch: 76.11min\n",
      "Est. Remaining Time Till Epoch: 75.59min\n",
      "Est. Remaining Time Till Epoch: 75.08min\n",
      "Est. Remaining Time Till Epoch: 74.54min\n",
      "Est. Remaining Time Till Epoch: 74.09min\n",
      "Est. Remaining Time Till Epoch: 73.49min\n",
      "Est. Remaining Time Till Epoch: 72.9min\n",
      "Est. Remaining Time Till Epoch: 72.31min\n",
      "Est. Remaining Time Till Epoch: 71.71min\n",
      "Est. Remaining Time Till Epoch: 71.13min\n",
      "Est. Remaining Time Till Epoch: 70.52min\n",
      "Est. Remaining Time Till Epoch: 69.95min\n",
      "Est. Remaining Time Till Epoch: 69.36min\n",
      "Est. Remaining Time Till Epoch: 68.77min\n",
      "Est. Remaining Time Till Epoch: 68.17min\n",
      "Est. Remaining Time Till Epoch: 67.6min\n",
      "Est. Remaining Time Till Epoch: 67.01min\n",
      "Est. Remaining Time Till Epoch: 66.42min\n",
      "Est. Remaining Time Till Epoch: 65.88min\n",
      "Est. Remaining Time Till Epoch: 65.36min\n",
      "Est. Remaining Time Till Epoch: 64.83min\n",
      "Est. Remaining Time Till Epoch: 64.3min\n",
      "Est. Remaining Time Till Epoch: 63.78min\n",
      "Est. Remaining Time Till Epoch: 63.27min\n",
      "Est. Remaining Time Till Epoch: 62.75min\n",
      "Est. Remaining Time Till Epoch: 62.2min\n",
      "Est. Remaining Time Till Epoch: 61.61min\n",
      "Est. Remaining Time Till Epoch: 61.05min\n",
      "Est. Remaining Time Till Epoch: 60.48min\n",
      "Est. Remaining Time Till Epoch: 59.91min\n",
      "Est. Remaining Time Till Epoch: 59.33min\n",
      "Est. Remaining Time Till Epoch: 58.76min\n",
      "Est. Remaining Time Till Epoch: 58.19min\n",
      "Est. Remaining Time Till Epoch: 57.62min\n",
      "Est. Remaining Time Till Epoch: 57.06min\n",
      "Est. Remaining Time Till Epoch: 56.72min\n",
      "Est. Remaining Time Till Epoch: 56.14min\n",
      "Est. Remaining Time Till Epoch: 55.57min\n",
      "Est. Remaining Time Till Epoch: 55.0min\n",
      "Est. Remaining Time Till Epoch: 54.43min\n",
      "Est. Remaining Time Till Epoch: 53.86min\n",
      "Est. Remaining Time Till Epoch: 53.28min\n",
      "Est. Remaining Time Till Epoch: 52.71min\n",
      "Est. Remaining Time Till Epoch: 52.14min\n",
      "Est. Remaining Time Till Epoch: 51.57min\n",
      "Est. Remaining Time Till Epoch: 51.01min\n",
      "Est. Remaining Time Till Epoch: 50.43min\n",
      "Est. Remaining Time Till Epoch: 49.86min\n",
      "Est. Remaining Time Till Epoch: 49.29min\n",
      "Est. Remaining Time Till Epoch: 48.73min\n",
      "Est. Remaining Time Till Epoch: 48.16min\n",
      "Est. Remaining Time Till Epoch: 47.58min\n",
      "Est. Remaining Time Till Epoch: 47.02min\n",
      "Est. Remaining Time Till Epoch: 46.45min\n",
      "Est. Remaining Time Till Epoch: 45.89min\n",
      "Est. Remaining Time Till Epoch: 45.32min\n",
      "Est. Remaining Time Till Epoch: 44.75min\n",
      "Est. Remaining Time Till Epoch: 44.19min\n",
      "Est. Remaining Time Till Epoch: 43.64min\n",
      "Est. Remaining Time Till Epoch: 43.07min\n",
      "Est. Remaining Time Till Epoch: 42.51min\n",
      "Est. Remaining Time Till Epoch: 41.95min\n",
      "Est. Remaining Time Till Epoch: 41.38min\n",
      "Est. Remaining Time Till Epoch: 40.82min\n",
      "Est. Remaining Time Till Epoch: 40.26min\n",
      "Est. Remaining Time Till Epoch: 39.7min\n",
      "Est. Remaining Time Till Epoch: 39.13min\n",
      "Est. Remaining Time Till Epoch: 38.57min\n",
      "Est. Remaining Time Till Epoch: 38.01min\n",
      "Est. Remaining Time Till Epoch: 37.45min\n",
      "Est. Remaining Time Till Epoch: 36.89min\n",
      "Est. Remaining Time Till Epoch: 36.33min\n",
      "Est. Remaining Time Till Epoch: 35.77min\n",
      "Est. Remaining Time Till Epoch: 35.21min\n",
      "Est. Remaining Time Till Epoch: 34.65min\n",
      "Est. Remaining Time Till Epoch: 34.09min\n",
      "Est. Remaining Time Till Epoch: 33.54min\n",
      "Est. Remaining Time Till Epoch: 32.97min\n",
      "Est. Remaining Time Till Epoch: 32.42min\n",
      "Est. Remaining Time Till Epoch: 31.86min\n",
      "Est. Remaining Time Till Epoch: 31.3min\n",
      "Est. Remaining Time Till Epoch: 30.74min\n",
      "Est. Remaining Time Till Epoch: 30.18min\n",
      "Est. Remaining Time Till Epoch: 29.63min\n",
      "Est. Remaining Time Till Epoch: 29.07min\n",
      "Est. Remaining Time Till Epoch: 28.51min\n",
      "Est. Remaining Time Till Epoch: 27.96min\n",
      "Est. Remaining Time Till Epoch: 27.4min\n",
      "Est. Remaining Time Till Epoch: 26.84min\n",
      "Est. Remaining Time Till Epoch: 26.28min\n",
      "Est. Remaining Time Till Epoch: 25.73min\n",
      "Est. Remaining Time Till Epoch: 25.17min\n",
      "Est. Remaining Time Till Epoch: 24.61min\n",
      "Est. Remaining Time Till Epoch: 24.06min\n",
      "Est. Remaining Time Till Epoch: 23.5min\n",
      "Est. Remaining Time Till Epoch: 22.95min\n",
      "Est. Remaining Time Till Epoch: 22.39min\n",
      "Est. Remaining Time Till Epoch: 21.83min\n",
      "Est. Remaining Time Till Epoch: 21.28min\n",
      "Est. Remaining Time Till Epoch: 20.72min\n",
      "Est. Remaining Time Till Epoch: 20.17min\n",
      "Est. Remaining Time Till Epoch: 19.61min\n",
      "Est. Remaining Time Till Epoch: 19.05min\n",
      "Est. Remaining Time Till Epoch: 18.5min\n",
      "Est. Remaining Time Till Epoch: 17.94min\n",
      "Est. Remaining Time Till Epoch: 17.39min\n",
      "Est. Remaining Time Till Epoch: 16.83min\n",
      "Est. Remaining Time Till Epoch: 16.28min\n",
      "Est. Remaining Time Till Epoch: 15.72min\n",
      "Est. Remaining Time Till Epoch: 15.17min\n",
      "Est. Remaining Time Till Epoch: 14.61min\n",
      "Est. Remaining Time Till Epoch: 14.06min\n",
      "Est. Remaining Time Till Epoch: 13.5min\n",
      "Est. Remaining Time Till Epoch: 12.95min\n",
      "Est. Remaining Time Till Epoch: 12.39min\n",
      "Est. Remaining Time Till Epoch: 11.84min\n",
      "Est. Remaining Time Till Epoch: 11.28min\n",
      "Est. Remaining Time Till Epoch: 10.73min\n",
      "Est. Remaining Time Till Epoch: 10.18min\n",
      "Est. Remaining Time Till Epoch: 9.62min\n",
      "Est. Remaining Time Till Epoch: 9.07min\n",
      "Est. Remaining Time Till Epoch: 8.51min\n",
      "Est. Remaining Time Till Epoch: 7.96min\n",
      "Est. Remaining Time Till Epoch: 7.4min\n",
      "Est. Remaining Time Till Epoch: 6.85min\n",
      "Est. Remaining Time Till Epoch: 6.3min\n",
      "Est. Remaining Time Till Epoch: 5.74min\n",
      "Est. Remaining Time Till Epoch: 5.19min\n",
      "Est. Remaining Time Till Epoch: 4.64min\n",
      "Est. Remaining Time Till Epoch: 4.08min\n",
      "Est. Remaining Time Till Epoch: 3.53min\n",
      "Est. Remaining Time Till Epoch: 2.97min\n",
      "Est. Remaining Time Till Epoch: 2.42min\n",
      "Est. Remaining Time Till Epoch: 1.87min\n",
      "Est. Remaining Time Till Epoch: 1.31min\n",
      "Est. Remaining Time Till Epoch: 0.76min\n",
      "Est. Remaining Time Till Epoch: 0.21min\n",
      "Est. Remaining Time Till Epoch: 0.0min\n",
      "Train loss: 0.09544503557737227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████▋                 | 2/3 [3:04:07<1:32:07, 5527.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  78.44254510921176\n",
      "Flat Validation Accuracy:  71.95121951219512\n",
      "Est. Remaining Time Till Epoch: 88.63min\n",
      "Est. Remaining Time Till Epoch: 87.68min\n",
      "Est. Remaining Time Till Epoch: 86.86min\n",
      "Est. Remaining Time Till Epoch: 86.37min\n",
      "Est. Remaining Time Till Epoch: 85.95min\n",
      "Est. Remaining Time Till Epoch: 85.31min\n",
      "Est. Remaining Time Till Epoch: 84.92min\n",
      "Est. Remaining Time Till Epoch: 84.38min\n",
      "Est. Remaining Time Till Epoch: 83.81min\n",
      "Est. Remaining Time Till Epoch: 83.27min\n",
      "Est. Remaining Time Till Epoch: 82.77min\n",
      "Est. Remaining Time Till Epoch: 82.21min\n",
      "Est. Remaining Time Till Epoch: 81.66min\n",
      "Est. Remaining Time Till Epoch: 81.09min\n",
      "Est. Remaining Time Till Epoch: 80.52min\n",
      "Est. Remaining Time Till Epoch: 80.02min\n",
      "Est. Remaining Time Till Epoch: 79.45min\n",
      "Est. Remaining Time Till Epoch: 78.87min\n",
      "Est. Remaining Time Till Epoch: 78.33min\n",
      "Est. Remaining Time Till Epoch: 77.77min\n",
      "Est. Remaining Time Till Epoch: 77.22min\n",
      "Est. Remaining Time Till Epoch: 76.67min\n",
      "Est. Remaining Time Till Epoch: 76.12min\n",
      "Est. Remaining Time Till Epoch: 75.56min\n",
      "Est. Remaining Time Till Epoch: 75.04min\n",
      "Est. Remaining Time Till Epoch: 74.46min\n",
      "Est. Remaining Time Till Epoch: 73.9min\n",
      "Est. Remaining Time Till Epoch: 73.35min\n",
      "Est. Remaining Time Till Epoch: 72.77min\n",
      "Est. Remaining Time Till Epoch: 72.22min\n",
      "Est. Remaining Time Till Epoch: 71.66min\n",
      "Est. Remaining Time Till Epoch: 71.1min\n",
      "Est. Remaining Time Till Epoch: 70.55min\n",
      "Est. Remaining Time Till Epoch: 70.02min\n",
      "Est. Remaining Time Till Epoch: 69.53min\n",
      "Est. Remaining Time Till Epoch: 68.98min\n",
      "Est. Remaining Time Till Epoch: 68.43min\n",
      "Est. Remaining Time Till Epoch: 67.88min\n",
      "Est. Remaining Time Till Epoch: 67.32min\n",
      "Est. Remaining Time Till Epoch: 66.77min\n",
      "Est. Remaining Time Till Epoch: 66.23min\n",
      "Est. Remaining Time Till Epoch: 65.67min\n",
      "Est. Remaining Time Till Epoch: 65.13min\n",
      "Est. Remaining Time Till Epoch: 64.59min\n",
      "Est. Remaining Time Till Epoch: 64.03min\n",
      "Est. Remaining Time Till Epoch: 63.49min\n",
      "Est. Remaining Time Till Epoch: 62.93min\n",
      "Est. Remaining Time Till Epoch: 62.39min\n",
      "Est. Remaining Time Till Epoch: 61.84min\n",
      "Est. Remaining Time Till Epoch: 61.29min\n",
      "Est. Remaining Time Till Epoch: 60.74min\n",
      "Est. Remaining Time Till Epoch: 60.2min\n",
      "Est. Remaining Time Till Epoch: 59.65min\n",
      "Est. Remaining Time Till Epoch: 59.1min\n",
      "Est. Remaining Time Till Epoch: 58.56min\n",
      "Est. Remaining Time Till Epoch: 57.99min\n",
      "Est. Remaining Time Till Epoch: 57.44min\n",
      "Est. Remaining Time Till Epoch: 56.88min\n",
      "Est. Remaining Time Till Epoch: 56.34min\n",
      "Est. Remaining Time Till Epoch: 55.79min\n",
      "Est. Remaining Time Till Epoch: 55.24min\n",
      "Est. Remaining Time Till Epoch: 54.68min\n",
      "Est. Remaining Time Till Epoch: 54.14min\n",
      "Est. Remaining Time Till Epoch: 53.58min\n",
      "Est. Remaining Time Till Epoch: 53.03min\n",
      "Est. Remaining Time Till Epoch: 52.49min\n",
      "Est. Remaining Time Till Epoch: 51.93min\n",
      "Est. Remaining Time Till Epoch: 51.38min\n",
      "Est. Remaining Time Till Epoch: 50.83min\n",
      "Est. Remaining Time Till Epoch: 50.28min\n",
      "Est. Remaining Time Till Epoch: 49.73min\n",
      "Est. Remaining Time Till Epoch: 49.18min\n",
      "Est. Remaining Time Till Epoch: 48.63min\n",
      "Est. Remaining Time Till Epoch: 48.08min\n",
      "Est. Remaining Time Till Epoch: 47.53min\n",
      "Est. Remaining Time Till Epoch: 46.97min\n",
      "Est. Remaining Time Till Epoch: 46.43min\n",
      "Est. Remaining Time Till Epoch: 45.88min\n",
      "Est. Remaining Time Till Epoch: 45.33min\n",
      "Est. Remaining Time Till Epoch: 44.78min\n",
      "Est. Remaining Time Till Epoch: 44.23min\n",
      "Est. Remaining Time Till Epoch: 43.68min\n",
      "Est. Remaining Time Till Epoch: 43.13min\n",
      "Est. Remaining Time Till Epoch: 42.58min\n",
      "Est. Remaining Time Till Epoch: 42.03min\n",
      "Est. Remaining Time Till Epoch: 41.48min\n",
      "Est. Remaining Time Till Epoch: 40.93min\n",
      "Est. Remaining Time Till Epoch: 40.38min\n",
      "Est. Remaining Time Till Epoch: 39.83min\n",
      "Est. Remaining Time Till Epoch: 39.28min\n",
      "Est. Remaining Time Till Epoch: 38.73min\n",
      "Est. Remaining Time Till Epoch: 38.18min\n",
      "Est. Remaining Time Till Epoch: 37.63min\n",
      "Est. Remaining Time Till Epoch: 37.08min\n",
      "Est. Remaining Time Till Epoch: 36.53min\n",
      "Est. Remaining Time Till Epoch: 35.98min\n",
      "Est. Remaining Time Till Epoch: 35.43min\n",
      "Est. Remaining Time Till Epoch: 34.88min\n",
      "Est. Remaining Time Till Epoch: 34.33min\n",
      "Est. Remaining Time Till Epoch: 33.78min\n",
      "Est. Remaining Time Till Epoch: 33.22min\n",
      "Est. Remaining Time Till Epoch: 32.67min\n",
      "Est. Remaining Time Till Epoch: 32.12min\n",
      "Est. Remaining Time Till Epoch: 31.57min\n",
      "Est. Remaining Time Till Epoch: 31.02min\n",
      "Est. Remaining Time Till Epoch: 30.47min\n",
      "Est. Remaining Time Till Epoch: 29.92min\n",
      "Est. Remaining Time Till Epoch: 29.37min\n",
      "Est. Remaining Time Till Epoch: 28.82min\n",
      "Est. Remaining Time Till Epoch: 28.27min\n",
      "Est. Remaining Time Till Epoch: 27.72min\n",
      "Est. Remaining Time Till Epoch: 27.17min\n",
      "Est. Remaining Time Till Epoch: 26.62min\n",
      "Est. Remaining Time Till Epoch: 26.07min\n",
      "Est. Remaining Time Till Epoch: 25.52min\n",
      "Est. Remaining Time Till Epoch: 24.97min\n",
      "Est. Remaining Time Till Epoch: 24.42min\n",
      "Est. Remaining Time Till Epoch: 23.87min\n",
      "Est. Remaining Time Till Epoch: 23.32min\n",
      "Est. Remaining Time Till Epoch: 22.77min\n",
      "Est. Remaining Time Till Epoch: 22.22min\n",
      "Est. Remaining Time Till Epoch: 21.67min\n",
      "Est. Remaining Time Till Epoch: 21.12min\n",
      "Est. Remaining Time Till Epoch: 20.57min\n",
      "Est. Remaining Time Till Epoch: 20.02min\n",
      "Est. Remaining Time Till Epoch: 19.47min\n",
      "Est. Remaining Time Till Epoch: 18.92min\n",
      "Est. Remaining Time Till Epoch: 18.37min\n",
      "Est. Remaining Time Till Epoch: 17.82min\n",
      "Est. Remaining Time Till Epoch: 17.27min\n",
      "Est. Remaining Time Till Epoch: 16.72min\n",
      "Est. Remaining Time Till Epoch: 16.16min\n",
      "Est. Remaining Time Till Epoch: 15.62min\n",
      "Est. Remaining Time Till Epoch: 15.07min\n",
      "Est. Remaining Time Till Epoch: 14.52min\n",
      "Est. Remaining Time Till Epoch: 13.97min\n",
      "Est. Remaining Time Till Epoch: 13.41min\n",
      "Est. Remaining Time Till Epoch: 12.86min\n",
      "Est. Remaining Time Till Epoch: 12.31min\n",
      "Est. Remaining Time Till Epoch: 11.76min\n",
      "Est. Remaining Time Till Epoch: 11.21min\n",
      "Est. Remaining Time Till Epoch: 10.66min\n",
      "Est. Remaining Time Till Epoch: 10.11min\n",
      "Est. Remaining Time Till Epoch: 9.56min\n",
      "Est. Remaining Time Till Epoch: 9.01min\n",
      "Est. Remaining Time Till Epoch: 8.46min\n",
      "Est. Remaining Time Till Epoch: 7.91min\n",
      "Est. Remaining Time Till Epoch: 7.36min\n",
      "Est. Remaining Time Till Epoch: 6.81min\n",
      "Est. Remaining Time Till Epoch: 6.26min\n",
      "Est. Remaining Time Till Epoch: 5.71min\n",
      "Est. Remaining Time Till Epoch: 5.16min\n",
      "Est. Remaining Time Till Epoch: 4.61min\n",
      "Est. Remaining Time Till Epoch: 4.06min\n",
      "Est. Remaining Time Till Epoch: 3.51min\n",
      "Est. Remaining Time Till Epoch: 2.96min\n",
      "Est. Remaining Time Till Epoch: 2.41min\n",
      "Est. Remaining Time Till Epoch: 1.86min\n",
      "Est. Remaining Time Till Epoch: 1.31min\n",
      "Est. Remaining Time Till Epoch: 0.76min\n",
      "Est. Remaining Time Till Epoch: 0.21min\n",
      "Est. Remaining Time Till Epoch: 0.0min\n",
      "Train loss: 0.07187579310050717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████████████████████████| 3/3 [4:36:08<00:00, 5522.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  81.56934306569343\n",
      "Flat Validation Accuracy:  77.87456445993031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Store our loss and accuracy for plotting\n",
    "train_loss_set = []\n",
    "num_labels=18\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 3\n",
    "\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "\n",
    "    # Training\n",
    "    start = time.time()\n",
    "\n",
    "    # Set our model to training mode (as opposed to evaluation mode)\n",
    "    model.train()\n",
    "\n",
    "    # Tracking variables\n",
    "    tr_loss = 0 #running loss\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    # Train the data for one epoch\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Add batch to GPU\n",
    "        #batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
    "        # Clear out the gradients (by default they accumulate)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # # Forward pass for multiclass classification\n",
    "        # outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        # loss = outputs[0]\n",
    "        # logits = outputs[1]\n",
    "\n",
    "        # Forward pass for multilabel classification\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        logits = outputs[0]\n",
    "        loss_func = BCEWithLogitsLoss() \n",
    "        loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
    "        # loss_func = BCELoss() \n",
    "        # loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
    "        train_loss_set.append(loss.item())  \n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        # Update tracking variables\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        \n",
    "        calculate_remaining_time(start, time.time(), nb_tr_examples)\n",
    "\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "\n",
    "    ###############################################################################\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    # Put model in evaluation mode to evaluate loss on the validation set\n",
    "    model.eval()\n",
    "\n",
    "    # Variables to gather full output\n",
    "    logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "\n",
    "    # Predict\n",
    "    for i, batch in enumerate(validation_dataloader):\n",
    "        #batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
    "        with torch.no_grad():\n",
    "            # Forward pass\n",
    "            outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "            b_logit_pred = outs[0]\n",
    "            pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "            b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "            pred_label = pred_label.to('cpu').numpy()\n",
    "            b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tokenized_texts.append(b_input_ids)\n",
    "        logit_preds.append(b_logit_pred)\n",
    "        true_labels.append(b_labels)\n",
    "        pred_labels.append(pred_label)\n",
    "\n",
    "    # Flatten outputs\n",
    "    pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "    true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    threshold = 0.50\n",
    "    pred_bools = [pl>threshold for pl in pred_labels]\n",
    "    true_bools = [tl==1 for tl in true_labels]\n",
    "    val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n",
    "    val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n",
    "\n",
    "    print('F1 Validation Accuracy: ', val_f1_accuracy)\n",
    "    print('Flat Validation Accuracy: ', val_flat_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-flower",
   "metadata": {},
   "source": [
    "#### Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "excited-venue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values:  False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comp_name</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07e45bf1b3a39e5d</td>\n",
       "      <td>engie</td>\n",
       "      <td>Our customers benefit from our energy-efficien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07e45bf1b3a39e5d</td>\n",
       "      <td>engie</td>\n",
       "      <td>ENGIE are recruiting for a Mobile Contract Sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07e45bf1b3a39e5d</td>\n",
       "      <td>engie</td>\n",
       "      <td>This is a permanent, full time role working 40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07e45bf1b3a39e5d</td>\n",
       "      <td>engie</td>\n",
       "      <td>On offer is a salary of £35,000 - £37,500 depe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07e45bf1b3a39e5d</td>\n",
       "      <td>engie</td>\n",
       "      <td>Safe Supervision of all personnel including th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id comp_name  \\\n",
       "0  07e45bf1b3a39e5d     engie   \n",
       "1  07e45bf1b3a39e5d     engie   \n",
       "2  07e45bf1b3a39e5d     engie   \n",
       "3  07e45bf1b3a39e5d     engie   \n",
       "4  07e45bf1b3a39e5d     engie   \n",
       "\n",
       "                                            sentence  \n",
       "0  Our customers benefit from our energy-efficien...  \n",
       "1  ENGIE are recruiting for a Mobile Contract Sup...  \n",
       "2  This is a permanent, full time role working 40...  \n",
       "3  On offer is a salary of £35,000 - £37,500 depe...  \n",
       "4  Safe Supervision of all personnel including th...  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('./data/dev_test_set_u.csv')\n",
    "print('Null values: ', test_df.isnull().values.any()) #should not be any null sentences or labels\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "piano-africa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values:  False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comp_name</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07e45bf1b3a39e5d</td>\n",
       "      <td>engie</td>\n",
       "      <td>Our customers benefit from our energy-efficien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07e45bf1b3a39e5d</td>\n",
       "      <td>engie</td>\n",
       "      <td>ENGIE are recruiting for a Mobile Contract Sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07e45bf1b3a39e5d</td>\n",
       "      <td>engie</td>\n",
       "      <td>This is a permanent, full time role working 40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07e45bf1b3a39e5d</td>\n",
       "      <td>engie</td>\n",
       "      <td>On offer is a salary of £35,000 - £37,500 depe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07e45bf1b3a39e5d</td>\n",
       "      <td>engie</td>\n",
       "      <td>Safe Supervision of all personnel including th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id comp_name  \\\n",
       "0  07e45bf1b3a39e5d     engie   \n",
       "1  07e45bf1b3a39e5d     engie   \n",
       "2  07e45bf1b3a39e5d     engie   \n",
       "3  07e45bf1b3a39e5d     engie   \n",
       "4  07e45bf1b3a39e5d     engie   \n",
       "\n",
       "                                            sentence  \n",
       "0  Our customers benefit from our energy-efficien...  \n",
       "1  ENGIE are recruiting for a Mobile Contract Sup...  \n",
       "2  This is a permanent, full time role working 40...  \n",
       "3  On offer is a salary of £35,000 - £37,500 depe...  \n",
       "4  Safe Supervision of all personnel including th...  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_test = pd.read_csv('./data/dev_test_set_u.csv')\n",
    "test_df = dev_test.iloc[:2000, :]\n",
    "print('Null values: ', test_df.isnull().values.any()) #should not be any null sentences or labels\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df = test_df[~test_df[test_label_cols].eq(-1).any(axis=1)] #remove irrelevant rows/comments with -1 values\n",
    "#test_df['one_hot_labels'] = list(test_df[test_label_cols].values)\n",
    "#test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cardiovascular-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering input data\n",
    "#test_labels = list(test_df.one_hot_labels.values)\n",
    "#test_comments = list(test_df.comment_text.values)\n",
    "test_sentences = list(test_df.sentence.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "metallic-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding input data\n",
    "test_encodings = tokenizer.batch_encode_plus(test_sentences, return_token_type_ids=True, padding=True)\n",
    "test_input_ids = test_encodings['input_ids']\n",
    "test_token_type_ids = test_encodings['token_type_ids']\n",
    "test_attention_masks = test_encodings['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "clear-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make tensors out of data\n",
    "test_inputs = torch.tensor(test_input_ids)\n",
    "#test_labels = torch.tensor(test_labels)\n",
    "test_masks = torch.tensor(test_attention_masks)\n",
    "test_token_types = torch.tensor(test_token_type_ids)\n",
    "# Create test dataloader\n",
    "#test_data = TensorDataset(test_inputs, test_masks, test_labels, test_token_types)\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_token_types)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "failing-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "def predict(sentence):\n",
    "    global counter\n",
    "    test_encodings = tokenizer.encode_plus(sentence, return_token_type_ids=True, padding=True)\n",
    "    b_input_ids = torch.tensor([test_encodings['input_ids']])\n",
    "    b_input_mask = torch.tensor([test_encodings['token_type_ids']])\n",
    "    b_token_types = torch.tensor([test_encodings['attention_mask']])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        b_logit_pred = outs[0]\n",
    "        pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "        b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "        pred_label = pred_label.to('cpu').numpy()\n",
    "        prediction = list(pred_label[0]).index(max(list(pred_label[0]))) \n",
    "        \n",
    "        counter += 1\n",
    "        if (counter % 10) == 0: \n",
    "            print(counter)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "economic-julian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78653"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "radical-concentration",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-128-001ab6cb5b4f>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['model_most_likely'] = test_df['sentence'].apply(lambda x: predict(x))\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_df['model_most_likely'] = test_df['sentence'].apply(lambda x: predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "geographic-passport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "a = dev_test.shape[0]\n",
    "merged = dev_test.merge(test_df[['sentence', 'model_most_likely']], on='sentence', how='outer')\n",
    "b = merged.shape[0]\n",
    "print(a == b)\n",
    "c = merged[~merged['model_most_likely'].isnull()].shape[0]\n",
    "print(c == 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "floating-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('./data/dev_test_set_u_prelabelled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "hydraulic-overhead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "Sentence:\n",
      "Purpose and overall relevance to the organization\n",
      "-----\n",
      "Most likely class: 0\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-0b65b38d9353>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m                   \u001b[1;34m'Most likely class: {}\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                   '-----\\n').format(s, p))\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mtrue_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Please enter correct class: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-----\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mtrue_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_hot_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\sdg-bert\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             )\n\u001b[1;32m--> 860\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\sdg-bert\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "# Put model in evaluation mode to evaluate loss on the validation set\n",
    "model.eval()\n",
    "\n",
    "#track variables\n",
    "logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "\n",
    "# Predict\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "    #batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_token_types = batch\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        b_logit_pred = outs[0]\n",
    "        pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "        b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "        pred_label = pred_label.to('cpu').numpy()\n",
    "\n",
    "        #b_labels = b_labels.to('cpu').numpy()\n",
    "        sentences = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False) for ids in b_input_ids]\n",
    "        preds = [list(pred).index(max(list(pred))) for pred in pred_label]\n",
    "        for s, p in zip(sentences, preds):\n",
    "            print(('-----\\n'\n",
    "                  'Sentence:\\n'\n",
    "                  '{}\\n'\n",
    "                  '-----\\n'\n",
    "                  'Most likely class: {}\\n'\n",
    "                  '-----\\n').format(s, p))\n",
    "            true_label = input('Please enter correct class: ')\n",
    "            print('-----\\n')\n",
    "            true_labels.append(list(one_hot_encode(int(true_label))))\n",
    "            print(true_labels)\n",
    "        \n",
    "    add_to_df\n",
    "        \n",
    "    tokenized_texts.append(b_input_ids)\n",
    "    logit_preds.append(b_logit_pred)\n",
    "    true_labels.append(b_labels)\n",
    "    pred_labels.append(pred_label)\n",
    "\n",
    "# Flatten outputs\n",
    "tokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n",
    "pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "true_labels = [item for sublist in true_labels for item in sublist]\n",
    "# Converting flattened binary values to boolean values\n",
    "true_bools = [tl==1 for tl in true_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-pulse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bools = [pl>0.50 for pl in pred_labels] #boolean output after thresholding\n",
    "\n",
    "# Print and save classification report\n",
    "print('Test F1 Accuracy: ', f1_score(true_bools, pred_bools,average='micro'))\n",
    "print('Test Flat Accuracy: ', accuracy_score(true_bools, pred_bools),'\\n')\n",
    "clf_report = classification_report(true_bools,pred_bools,target_names=test_label_cols)\n",
    "pickle.dump(clf_report, open('classification_report.txt','wb')) #save report\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-exhaust",
   "metadata": {},
   "source": [
    "#### Create Output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label = dict(zip(range(18),label_cols))\n",
    "print(idx2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting indices of where boolean one hot vector true_bools is True so we can use idx2label to gather label names\n",
    "true_label_idxs, pred_label_idxs=[],[]\n",
    "for vals in true_bools:\n",
    "    true_label_idxs.append(np.where(vals)[0].flatten().tolist())\n",
    "for vals in pred_bools:\n",
    "    pred_label_idxs.append(np.where(vals)[0].flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding input ids to comment text\n",
    "comment_texts = [tokenizer.decode(text,skip_special_tokens=True,clean_up_tokenization_spaces=False) for text in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting lists to df\n",
    "comparisons_df = pd.DataFrame({'comment_text': comment_texts, 'true_labels': true_label_texts, 'pred_labels':pred_label_texts})\n",
    "comparisons_df.to_csv('comparisons.csv')\n",
    "comparisons_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-shooting",
   "metadata": {},
   "source": [
    "#### Optimize Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering vectors of label names using idx2label\n",
    "true_label_texts, pred_label_texts = [], []\n",
    "for vals in true_label_idxs:\n",
    "    if vals:\n",
    "    true_label_texts.append([idx2label[val] for val in vals])\n",
    "    else:\n",
    "    true_label_texts.append(vals)\n",
    "\n",
    "for vals in pred_label_idxs:\n",
    "    if vals:\n",
    "    pred_label_texts.append([idx2label[val] for val in vals])\n",
    "    else:\n",
    "    pred_label_texts.append(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Accuracy - maximize F1 accuracy by tuning threshold values. First with 'macro_thresholds' on the order of e^-1 then with 'micro_thresholds' on the order of e^-2\n",
    "\n",
    "macro_thresholds = np.array(range(1,10))/10\n",
    "\n",
    "f1_results, flat_acc_results = [], []\n",
    "for th in macro_thresholds:\n",
    "    pred_bools = [pl>th for pl in pred_labels]\n",
    "    test_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')\n",
    "    test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
    "    f1_results.append(test_f1_accuracy)\n",
    "    flat_acc_results.append(test_flat_accuracy)\n",
    "\n",
    "best_macro_th = macro_thresholds[np.argmax(f1_results)] #best macro threshold value\n",
    "\n",
    "micro_thresholds = (np.array(range(10))/100)+best_macro_th #calculating micro threshold values\n",
    "\n",
    "f1_results, flat_acc_results = [], []\n",
    "for th in micro_thresholds:\n",
    "    pred_bools = [pl>th for pl in pred_labels]\n",
    "    test_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')\n",
    "    test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
    "    f1_results.append(test_f1_accuracy)\n",
    "    flat_acc_results.append(test_flat_accuracy)\n",
    "\n",
    "best_f1_idx = np.argmax(f1_results) #best threshold value\n",
    "\n",
    "# Printing and saving classification report\n",
    "print('Best Threshold: ', micro_thresholds[best_f1_idx])\n",
    "print('Test F1 Accuracy: ', f1_results[best_f1_idx])\n",
    "print('Test Flat Accuracy: ', flat_acc_results[best_f1_idx], '\\n')\n",
    "\n",
    "best_pred_bools = [pl>micro_thresholds[best_f1_idx] for pl in pred_labels]\n",
    "clf_report_optimized = classification_report(true_bools,best_pred_bools, target_names=label_cols)\n",
    "pickle.dump(clf_report_optimized, open('classification_report_optimized.txt','wb'))\n",
    "print(clf_report_optimized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
